## Jaringan Saraf dengan Menggunakan Keras

> Jaringan saraf tiruan (Artificial Neural Network) adalah model pembelajaran mesin yang terinspirasi dari cara kerja otak manusia. Dalam bagian ini, kita akan membahas bagaimana membangun model jaringan saraf sederhana menggunakan Keras, sebuah API deep learning berbasis TensorFlow.

### Model Linear dengan Keras

Pada model linier yang telah kita bahas di bagian sebelumnya, kita menuliskan model Keras sebagai berikut:

```python
import tensorflow as tf

model = tf.keras.Sequential([
    tf.keras.layers.Flatten(input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)),
    tf.keras.layers.Dense(len(CLASS_NAMES), activation='softmax')
])
```
> Model ini terdiri dari dua lapisan:
> - Flatten: Mengubah input gambar menjadi vektor satu dimensi.
> - Dense (Softmax): Lapisan output dengan jumlah unit sesuai jumlah kelas, menggunakan fungsi aktivasi softmax.

Output dari model dihitung sebagai softmax dari rata-rata bobot input yang telah diratakan:

$$
Y = \text{softmax} \left( B + \sum_\text{pixels} W_j X_j \right)
$$

Di mana:

 - **_B_** adalah bias,
 - **_W_** adalah bobot,
 - **_X_** adalah input, dan
 - **_Y_** adalah output tensor.

Hal ini biasanya ditulis dalam bentuk matriks sebagai (menggunakan § untuk mewakili softmax):

Dalam bentuk matriks: 

$$
Y = \text{§} \left( B + WX \right)
$$

> Struktur Model & Parameter

Model yang kita buat hanya memiliki satu lapisan trainable (Dense), sementara Flatten hanya berfungsi sebagai operasi reshaping:

```python
Layer (type)              Output Shape         Param #  
=======================================================
flatten_1 (Flatten)       (None, 150528)       0      
dense_1 (Dense)          (None, 5)            752645  
=======================================================

```
Model Linear saja sudah bagus, tetapi itu masih menunjukkan keterbatasan dalam pembuatan modelnya. Bagaimana kita bisa membuat model yang lebih kompleks?

### Jaringan Saraf

Untuk membuat model yang lebih kompleks, kita dapat menambahkan satu atau lebih lapisan Dense di antara input dan output. Hasilnya dalam pemodelan Machine Learning disebut Jaringan Saraf atau a _Neural Network_, untuk selengkapnya akan kita jelaskan secara singkat.

**Menambahkan Hidden Layer**

```python

model = tf.keras.Sequential([
    tf.keras.layers.Flatten(input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)),
    tf.keras.layers.Dense(128),
    tf.keras.layers.Dense(len(CLASS_NAMES), activation='softmax')
])
```

Sekarang, model memiliki tiga lapisan:

> - Flatten (meratakan input),
> - Dense (Hidden Layer, 128 unit, dengan bobot yang bisa dilatih),
> - Dense (Output, menggunakan softmax).

Lapisan hidden layer ini memungkinkan model untuk menangkap pola yang lebih kompleks. Lapisan tersembunyi atau _a Hidden Layer_ adalah lapisan dengan bobot yang dapat dilatih, seperti yang kita tambahkan, yang tidak merupakan lapisan input atau output.

```python

| Layer      | Input Shape      | Output Shape   |
|------------|----------------|---------------|
| Input      | (None, 224, 224, 3) | (None, 224, 224, 3) |
| Flatten    | (None, 224, 224, 3) | (None, 150528) |
| Dense      | (None, 150528) | (None, 128) |
| Dense      | (None, 128) | (None, 5) |

```
Matematis, outputnya sekarang adalah:
```math
Y = \sigma(B_2 + W_2(B_1 + W_1X))
```

Membungkus beberapa lapisan seperti ini sebenarnya tidak ada gunanya, karena kita bisa saja langsung mengalikan bobot lapisan kedua \( W_2 \) ke dalam persamaan—model tetap menjadi model linier.

Namun, jika kita menambahkan **fungsi aktivasi non-linear** \( A(x) \) untuk mentransformasikan output dari lapisan tersembunyi, maka persamaannya menjadi:

```math
Y = \sigma(B_2 + W_2 A(B_1 + W_1X))
```

Dengan demikian, output model menjadi mampu merepresentasikan hubungan yang lebih kompleks dibandingkan dengan fungsi linear sederhana.

Di Keras, kami memperkenalkan fungsi aktivasi sebagai berikut:

```pyhton
model = tf.keras.Sequential([
 tf.keras.layers.Flatten(input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)),
 tf.keras.layers.Dense(128, activation='relu'),
 tf.keras.layers.Dense(len(CLASS_NAMES), activation='softmax')
])
```
Fungsi **Rectified Linear Unit (ReLU)** adalah fungsi aktivasi yang paling umum digunakan untuk **lapisan tersembunyi** (lihat Gambar 2-15). Fungsi aktivasi lain yang juga sering digunakan termasuk **sigmoid, tanh, dan elu**.

![Deskripsi Gambar](https://github.com/zakariarafi/learning-computer-vision-indonesia-garuda/blob/main/2%20ML%20Models%20for%20Visions/Image%20%7C%20A%20few%20nonlinear%20activation%20functions.jpg?raw=true)

Ketiga fungsi aktivasi yang ditampilkan pada gambar di atas secara longgar didasarkan pada cara neuron di otak manusia menyala ketika input dari dendrit secara bersama-sama melebihi ambang batas minimum tertentu (lihat Gambar 2-16). Oleh karena itu, sebuah model yang memiliki lapisan tersembunyi dengan fungsi aktivasi nonlinier disebut sebagai “jaringan saraf” (neural network).

![Deskripsi Gambar](https://github.com/zakariarafi/learning-computer-vision-indonesia-garuda/blob/main/2%20ML%20Models%20for%20Visions/Image%20%7C%20A%20few%20nonlinear%20activation%20functions.jpg?raw=true)
