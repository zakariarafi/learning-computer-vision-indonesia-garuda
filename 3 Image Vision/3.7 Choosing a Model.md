### Memilih sebuah Model

Di bagian ini akan memberikan beberapa tips tentang cara memilih arsitektur model untuk tugas Anda. Pertama-tama, buatlah tolok ukur menggunakan layanan tanpa kode untuk melatih model ML, sehingga Anda memiliki gambaran yang baik tentang tingkat akurasi yang dapat dicapai pada masalah Anda. Jika Anda melatih di Google Cloud, pertimbangkan untuk menggunakan **Google Cloud AutoML**, yang memanfaatkan **neural architecture search (NAS)**. Jika Anda menggunakan **Microsoft Azure**, pertimbangkan untuk menggunakan **Custom Vision AI**. **DataRobot** dan **H2O.ai** menggunakan **transfer learning** untuk klasifikasi gambar tanpa kode. Kemungkinan besar, Anda tidak akan mendapatkan akurasi yang jauh lebih tinggi daripada yang disediakan oleh layanan ini secara langsung. Oleh karena itu, Anda dapat menggunakannya sebagai cara untuk dengan cepat membuat **proof of concept** sebelum menginvestasikan terlalu banyak waktu pada masalah yang mungkin tidak dapat diselesaikan.

**Perbandingan Performa**  
Mari kita rangkum angka-angka performa yang telah kita lihat sejauh ini, pertama untuk **fine-tuning** (Tabel 3-11). Perhatikan ada entri baru di bagian bawah yang disebut **"ensemble."** Kita akan membahas ini di bagian berikutnya.

Tabel 3-11. Delapan arsitektur model disempurnakan pada dataset 104 bunga

| Model         | Parameters (excl. classification head) | ImageNet accuracy | 104 flowers F1 score (fine-tuning) |
|--------------|----------------------------------------|------------------|-------------------------------------|
| EfficientNetB6 | 40M                                    | 84%              | 95.5%                               |
| EfficientNetB7 | 64M                                    | 84%              | 95.5%                               |
| DenseNet201    | 18M                                    | 77%              | 95.4%                               |
| Xception        | 21M                                    | 79%              | 94.6%                               |
| InceptionV3      | 22M                                    | 78%              | 94.6%                               |
| ResNet50         | 23M                                    | 75%              | 94.1%                               |
| MobileNetV2      | 2.3M                                   | 71%              | 92%                                 |
| NASNetLarge     | 85M                                    | 82%              | 89%                                 |
| VGG19            | 20M                                    | 71%              | 88%                                 |
| Ensemble         | 79M (DenseNet210 + Xception + EfficientNetB6) | -                | 96.2%                               |

> a. Tidak termasuk kepala klasifikasi dari jumlah parameter untuk memudahkan perbandingan antar arsitektur. Tanpa kepala klasifikasi, jumlah parameter dalam jaringan tidak bergantung pada resolusi. Selain itu, dalam contoh penyempurnaan, kepala klasifikasi yang berbeda dapat digunakan.
> 
> b. Untuk nilai akurasi, presisi, perolehan kembali, dan skor F1, semakin tinggi semakin baik.

Dan sekarang untuk pelatihan dari awal (Tabel 3-12). Karena fine-tuning bekerja jauh lebih baik pada dataset 104 bunga, tidak semua model telah dilatih dari awal.

Tabel 3-12. Enam arsitektur model dilatih dari awal pada dataset 104 bunga

| Model                 | Parameters (excl. classification head) | ImageNet accuracy | 104 flowers F1 score (trained from scratch) |
|-----------------------|----------------------------------------|------------------|---------------------------------------------|
| Xception              | 21M                                    | 79%              | 82.6%                                       |
| SqueezeNet, 24 layers | 2.7M                                   | -                | 76.2%                                       |
| DenseNet121           | 7M                                     | 75%              | 76.1%                                       |
| ResNet50              | 23M                                    | 75%              | 73%                                         |
| EfficientNetB4        | 18M                                    | 83%              | 69%                                         |
| AlexNet               | 3.7M                                   | 60%              | 39%                                         |

> a. Tidak termasuk kepala klasifikasi dari jumlah parameter untuk memudahkan perbandingan antar arsitektur. Tanpa kepala klasifikasi, jumlah parameter dalam jaringan tidak bergantung pada resolusi. Selain itu, dalam contoh penyempurnaan, kepala klasifikasi yang berbeda dapat digunakan.
>
> b. Untuk nilai akurasi, presisi, perolehan kembali, dan skor F1, semakin tinggi semakin baik.

Mengingat ini bukanlah arsitektur terbaru, Xception menjadi yang pertama.  Dalam makalahnya, penulis Xception mengatakan bahwa modelnya tampak lebih baik ketika diterapkan pada kumpulan data dunia nyata selain ImageNet dan kumpulan data konvensional akademis lainnya. Sangat penting bahwa model seperti SqueezeNet, yang dibuat dengan cepat oleh penulis buku, menempati posisi kedua.  SqueezeNet cukup efisien dan sangat mudah dikodekan jika Anda ingin mencoba arsitektur Anda sendiri.  Selain itu, model terkecil dari pilihan tersebut.  Kumpulan data 104 bunga, yang terdiri dari sekitar 20 ribu gambar, memiliki ukuran yang relatif kecil, sehingga ukurannya mungkin sangat sesuai.  DenseNet berada di urutan kedua, di belakang SqueezeNet, karena merupakan arsitektur yang paling tidak konvensional yang tersedia untuk pilihan ini. Namun, arsitektur ini tampaknya memiliki banyak potensi untuk kumpulan data yang tidak konvensional. Kirim input ke panel samping History Saved.
