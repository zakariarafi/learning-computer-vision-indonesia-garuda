## Memilih sebuah Model

Berikut beberapa tips memilih arsitektur model ML: Gunakan layanan tanpa kode untuk tolok ukur akurasi awal. Jika memakai **Google Cloud**, coba **AutoML** dengan **neural architecture search (NAS)**. Untuk **Microsoft Azure**, gunakan **Custom Vision AI**. **DataRobot** dan **H2O.ai** menawarkan **transfer learning** untuk klasifikasi gambar. Hasilnya biasanya mendekati akurasi maksimal, sehingga layanan ini bisa dimanfaatkan untuk **proof of concept** sebelum investasi lebih lanjut.

### **Perbandingan Performa**
___

Mari kita rangkum angka-angka performa yang telah kita lihat sejauh ini, pertama untuk **fine-tuning** (Tabel 3-11). Perhatikan ada entri baru di bagian bawah yang disebut **"ensemble."** Kita akan membahas ini di bagian berikutnya.

Tabel 3-11. Delapan arsitektur model disempurnakan pada dataset 104 bunga

| Model         | Parameters (excl. classification head) | ImageNet accuracy | 104 flowers F1 score (fine-tuning) |
|--------------|----------------------------------------|------------------|-------------------------------------|
| EfficientNetB6 | 40M                                    | 84%              | 95.5%                               |
| EfficientNetB7 | 64M                                    | 84%              | 95.5%                               |
| DenseNet201    | 18M                                    | 77%              | 95.4%                               |
| Xception        | 21M                                    | 79%              | 94.6%                               |
| InceptionV3      | 22M                                    | 78%              | 94.6%                               |
| ResNet50         | 23M                                    | 75%              | 94.1%                               |
| MobileNetV2      | 2.3M                                   | 71%              | 92%                                 |
| NASNetLarge     | 85M                                    | 82%              | 89%                                 |
| VGG19            | 20M                                    | 71%              | 88%                                 |
| Ensemble         | 79M (DenseNet210 + Xception + EfficientNetB6) | -                | 96.2%                               |

> a. Tidak termasuk kepala klasifikasi dari jumlah parameter untuk memudahkan perbandingan antar arsitektur. Tanpa kepala klasifikasi, jumlah parameter dalam jaringan tidak bergantung pada resolusi. Selain itu, dalam contoh penyempurnaan, kepala klasifikasi yang berbeda dapat digunakan.
> 
> b. Untuk nilai akurasi, presisi, perolehan kembali, dan skor F1, semakin tinggi semakin baik.

Dan sekarang untuk pelatihan dari awal (Tabel 3-12). Karena fine-tuning bekerja jauh lebih baik pada dataset 104 bunga, tidak semua model telah dilatih dari awal.

Tabel 3-12. Enam arsitektur model dilatih dari awal pada dataset 104 bunga

| Model                 | Parameters (excl. classification head) | ImageNet accuracy | 104 flowers F1 score (trained from scratch) |
|-----------------------|----------------------------------------|------------------|---------------------------------------------|
| Xception              | 21M                                    | 79%              | 82.6%                                       |
| SqueezeNet, 24 layers | 2.7M                                   | -                | 76.2%                                       |
| DenseNet121           | 7M                                     | 75%              | 76.1%                                       |
| ResNet50              | 23M                                    | 75%              | 73%                                         |
| EfficientNetB4        | 18M                                    | 83%              | 69%                                         |
| AlexNet               | 3.7M                                   | 60%              | 39%                                         |

> a. Tidak termasuk kepala klasifikasi dari jumlah parameter untuk memudahkan perbandingan antar arsitektur. Tanpa kepala klasifikasi, jumlah parameter dalam jaringan tidak bergantung pada resolusi. Selain itu, dalam contoh penyempurnaan, kepala klasifikasi yang berbeda dapat digunakan.
>
> b. Untuk nilai akurasi, presisi, perolehan kembali, dan skor F1, semakin tinggi semakin baik.

Xception menjadi yang pertama karena unggul pada data dunia nyata di luar ImageNet. **SqueezeNet** menempati posisi kedua karena efisien, mudah dikodekan, dan cocok untuk dataset kecil seperti **104 Flowers**. **DenseNet** berada di urutan berikutnya, menawarkan potensi untuk dataset tidak konvensional.  

Untuk model terbaru, cek **TensorFlow Hub**, karena sejak Januari 2021, **EfficientNet** adalah yang terbaru, tetapi mungkin ada yang lebih baru. Menggunakan beberapa model sekaligus juga bisa menjadi solusi, yang akan dibahas lebih lanjut nanti.

### **Ensembling/Merakit**
___

Untuk akurasi maksimal tanpa batasan ukuran atau waktu inferensi, beberapa model bisa digabungkan (**ensemble**) untuk prediksi lebih baik dan lebih relevan di dunia nyata. Pilih model dengan arsitektur berbeda agar kelemahan masing-masing saling mengimbangi.

Sebuah catatan, _03z_ensemble_finetune_flowers104.ipynb_, yang tersedia di repositori GitHub, menampilkan kombinasi dari tiga model yang sangat baik disusun pada dataset 104 bunga: DenseNet210, Xception, dan EfficientNetB6.  
 
 Tabel 3-13 menunjukkan bahwa grup menang dengan margin yang cukup besar.  Perbandingan antara model yang mirip dan model yang terpisah

 | Model         | Parameters (excl. classification head) | ImageNet accuracy | 104 flowers F1 score (fine-tuning) |
|--------------|----------------------------------------|------------------|-------------------------------------|
| EfficientNetB6 | 40M                                    | 84%              | 95.5%                               |
| DenseNet201    | 18M                                    | 77%              | 95.4%                               |
| Xception        | 21M                                    | 79%              | 94.6%                               |
| Ensemble         | 79M                                    | -                | 96.2%                               |
> a. Untuk memudahkan perbandingan antar arsitektur, kepala klasifikasi dihilangkan dari jumlah parameter. Tanpa kepala klasifikasi, jumlah parameter dalam jaringan tidak bergantung pada resolusi, dan beberapa kepala klasifikasi dapat digunakan dalam contoh penyempurnaan.  >
>
> b. Semakin tinggi nilai untuk akurasi, presisi, perolehan kembali, dan skor F1, semakin baik.

Cara termudah untuk menggabungkan ketiga model tersebut adalah dengan merata-ratakan probabilitas kelas yang diprediksi. Kemungkinan lain, yang secara teoritis lebih baik, adalah merata-ratakan logit (output lapisan terakhir sebelum aktivasi softmax) dan menerapkan softmax pada rata-rata untuk menghitung probabilitas kelas. Buku catatan contoh menunjukkan kedua opsi tersebut. Pada set data 104 bunga, kinerjanya sama.

| Informasi                                                                                       |
|-------------------------------------------------------------------------------------------------|
| Satu hal yang perlu diperhatikan saat merata-ratakan logit adalah bahwa logit, berbeda dengan probabilitas, tidak dinormalisasi. Logit dapat memiliki nilai yang sangat berbeda dalam model yang berbeda. Menghitung rata-rata tertimbang alih-alih rata-rata sederhana dapat membantu dalam kasus tersebut. Kumpulan data pelatihan harus digunakan untuk menghitung bobot terbaik. |

### Strategi Mengatasi Masalah Visi Komputer

#### **1. Pilih Metode Pelatihan Sesuai Ukuran Dataset:**  
- **< 1.000 gambar/label** → Gunakan **transfer learning**  
- **1.000 – 5.000 gambar/label** → Gunakan **fine-tuning**  
- **> 5.000 gambar/label** → **Latih model dari awal**  

Angka ini fleksibel tergantung kompleksitas model, kasus penggunaan, dan kualitas data. Cobalah beberapa pendekatan untuk hasil optimal.  

#### **2. Pilih Arsitektur Model Sesuai Kebutuhan:**  
- **SqueezeNet** → Model sederhana, cocok jika ingin membuat lapisan sendiri  
- **MobileNetV2** → Efisien untuk perangkat edge dengan daya rendah  
- **EfficientNet** → Model canggih untuk inferensi di cloud tanpa batasan kecepatan/ukuran  
- **ResNet50** → Pilihan stabil bagi organisasi konservatif  

Jika **akurasi lebih tinggi** diperlukan tanpa batasan biaya atau latensi, gunakan **ensemble** dari beberapa model.

| Kesimpulan                                                                                       |
|-------------------------------------------------------------------------------------------------|
| Bagian ini berfokus pada metode untuk mengklasifikasikan gambar.  Pertama, dijelaskan bagaimana menggunakan model yang telah dilatih sebelumnya dan mengadaptasinya ke set data baru. Ini adalah metode yang paling umum dan berhasil jika set data pra-pelatihan dan set data target memiliki setidaknya beberapa kesamaan. Kami mempelajari dua bentuk metode ini: pembelajaran transfer, di mana model yang telah dilatih sebelumnya dibekukan dan digunakan sebagai enkoder gambar statis; dan penyempurnaan, di mana bobot model yang telah dilatih sebelumnya digunakan sebagai nilai awal dalam pelatihan baru yang dilakukan pada set data baru.  Kami kemudian meninjau arsitektur klasifikasi gambar AlexNet dan EfficientNet yang paling baru dan lama. Untuk memberi Anda pemahaman lengkap tentang cara kerja model ini, semua blok penyusun arsitektur ini dijelaskan, tentu saja dimulai dengan lapisan konvolusional. Di Bab 4, kita akan melihat penggunaan salah satu arsitektur model gambar ini untuk memecahkan masalah visi komputer umum. |
