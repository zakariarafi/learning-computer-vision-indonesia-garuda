### Memilih sebuah Model

Di bagian ini akan memberikan beberapa tips tentang cara memilih arsitektur model untuk tugas Anda. Pertama-tama, buatlah tolok ukur menggunakan layanan tanpa kode untuk melatih model ML, sehingga Anda memiliki gambaran yang baik tentang tingkat akurasi yang dapat dicapai pada masalah Anda. Jika Anda melatih di Google Cloud, pertimbangkan untuk menggunakan **Google Cloud AutoML**, yang memanfaatkan **neural architecture search (NAS)**. Jika Anda menggunakan **Microsoft Azure**, pertimbangkan untuk menggunakan **Custom Vision AI**. **DataRobot** dan **H2O.ai** menggunakan **transfer learning** untuk klasifikasi gambar tanpa kode. Kemungkinan besar, Anda tidak akan mendapatkan akurasi yang jauh lebih tinggi daripada yang disediakan oleh layanan ini secara langsung. Oleh karena itu, Anda dapat menggunakannya sebagai cara untuk dengan cepat membuat **proof of concept** sebelum menginvestasikan terlalu banyak waktu pada masalah yang mungkin tidak dapat diselesaikan.

**Perbandingan Performa**  
Mari kita rangkum angka-angka performa yang telah kita lihat sejauh ini, pertama untuk **fine-tuning** (Tabel 3-11). Perhatikan ada entri baru di bagian bawah yang disebut **"ensemble."** Kita akan membahas ini di bagian berikutnya.

Tabel 3-11. Delapan arsitektur model disempurnakan pada dataset 104 bunga

| Model         | Parameters (excl. classification head) | ImageNet accuracy | 104 flowers F1 score (fine-tuning) |
|--------------|----------------------------------------|------------------|-------------------------------------|
| EfficientNetB6 | 40M                                    | 84%              | 95.5%                               |
| EfficientNetB7 | 64M                                    | 84%              | 95.5%                               |
| DenseNet201    | 18M                                    | 77%              | 95.4%                               |
| Xception        | 21M                                    | 79%              | 94.6%                               |
| InceptionV3      | 22M                                    | 78%              | 94.6%                               |
| ResNet50         | 23M                                    | 75%              | 94.1%                               |
| MobileNetV2      | 2.3M                                   | 71%              | 92%                                 |
| NASNetLarge     | 85M                                    | 82%              | 89%                                 |
| VGG19            | 20M                                    | 71%              | 88%                                 |
| Ensemble         | 79M (DenseNet210 + Xception + EfficientNetB6) | -                | 96.2%                               |

> a. Tidak termasuk kepala klasifikasi dari jumlah parameter untuk memudahkan perbandingan antar arsitektur. Tanpa kepala klasifikasi, jumlah parameter dalam jaringan tidak bergantung pada resolusi. Selain itu, dalam contoh penyempurnaan, kepala klasifikasi yang berbeda dapat digunakan.
> 
> b. Untuk nilai akurasi, presisi, perolehan kembali, dan skor F1, semakin tinggi semakin baik.

Dan sekarang untuk pelatihan dari awal (Tabel 3-12). Karena fine-tuning bekerja jauh lebih baik pada dataset 104 bunga, tidak semua model telah dilatih dari awal.

Tabel 3-12. Enam arsitektur model dilatih dari awal pada dataset 104 bunga

| Model                 | Parameters (excl. classification head) | ImageNet accuracy | 104 flowers F1 score (trained from scratch) |
|-----------------------|----------------------------------------|------------------|---------------------------------------------|
| Xception              | 21M                                    | 79%              | 82.6%                                       |
| SqueezeNet, 24 layers | 2.7M                                   | -                | 76.2%                                       |
| DenseNet121           | 7M                                     | 75%              | 76.1%                                       |
| ResNet50              | 23M                                    | 75%              | 73%                                         |
| EfficientNetB4        | 18M                                    | 83%              | 69%                                         |
| AlexNet               | 3.7M                                   | 60%              | 39%                                         |

> a. Tidak termasuk kepala klasifikasi dari jumlah parameter untuk memudahkan perbandingan antar arsitektur. Tanpa kepala klasifikasi, jumlah parameter dalam jaringan tidak bergantung pada resolusi. Selain itu, dalam contoh penyempurnaan, kepala klasifikasi yang berbeda dapat digunakan.
>
> b. Untuk nilai akurasi, presisi, perolehan kembali, dan skor F1, semakin tinggi semakin baik.

Mengingat ini bukanlah arsitektur terbaru, Xception menjadi yang pertama.  Dalam makalahnya, penulis Xception mengatakan bahwa modelnya tampak lebih baik ketika diterapkan pada kumpulan data dunia nyata selain ImageNet dan kumpulan data konvensional akademis lainnya. Sangat penting bahwa model seperti SqueezeNet, yang dibuat dengan cepat oleh penulis buku, menempati posisi kedua.  SqueezeNet cukup efisien dan sangat mudah dikodekan jika Anda ingin mencoba arsitektur Anda sendiri.  Selain itu, model terkecil dari pilihan tersebut.  Kumpulan data 104 bunga, yang terdiri dari sekitar 20 ribu gambar, memiliki ukuran yang relatif kecil, sehingga ukurannya mungkin sangat sesuai.  DenseNet berada di urutan kedua, di belakang SqueezeNet, karena merupakan arsitektur yang paling tidak konvensional yang tersedia untuk pilihan ini. Namun, arsitektur ini tampaknya memiliki banyak potensi untuk kumpulan data yang tidak konvensional. Kirim input ke panel samping History Saved.

Untuk memilih yang paling sesuai dan terkini, mungkin ada baiknya melihat variasi dan versi lain dari model ini.  Seperti yang disebutkan sebelumnya, saat menulis buku ini, EfficientNet adalah model terbaru (Januari 2021).  Saat Anda membacanya, mungkin ada sesuatu yang lebih baru.  Untuk model baru, Anda dapat melihat TensorFlow Hub.  Menggunakan beberapa model sekaligus adalah metode terakhir.  Kita akan membahasnya di kemudian hari.

**Ensembling/Merakit**
Ketika mencari akurasi maksimum dan saat ukuran dan waktu inferensi model tidak menjadi masalah, beberapa model dapat digunakan pada saat yang sama dan prediksi mereka digabungkan. Model ensemble tersebut sering kali dapat memberikan prediksi yang lebih baik daripada model mana pun yang menyusunnya.  Selain itu, mereka lebih mampu memprediksi situasi dalam kehidupan nyata. Memilih model yang sebisa mungkin berbeda satu sama lain adalah faktor utama saat memilih model untuk kelompok.  Kelemahan model yang memiliki arsitektur yang sangat berbeda lebih cenderung berbeda.  Selama kelompok tidak berada dalam kelas yang sama, kekuatan dan kelemahan model yang berbeda akan saling mengimbangi saat digabungkan.

Sebuah catatan, _03z_ensemble_finetune_flowers104.ipynb_, yang tersedia di repositori GitHub, menampilkan kombinasi dari tiga model yang sangat baik disusun pada dataset 104 bunga: DenseNet210, Xception, dan EfficientNetB6.  
 
 Tabel 3-13 menunjukkan bahwa grup menang dengan margin yang cukup besar.  Perbandingan antara model yang mirip dan model yang terpisah

 | Model         | Parameters (excl. classification head) | ImageNet accuracy | 104 flowers F1 score (fine-tuning) |
|--------------|----------------------------------------|------------------|-------------------------------------|
| EfficientNetB6 | 40M                                    | 84%              | 95.5%                               |
| DenseNet201    | 18M                                    | 77%              | 95.4%                               |
| Xception        | 21M                                    | 79%              | 94.6%                               |
| Ensemble         | 79M                                    | -                | 96.2%                               |
> a. Untuk memudahkan perbandingan antar arsitektur, kepala klasifikasi dihilangkan dari jumlah parameter. Tanpa kepala klasifikasi, jumlah parameter dalam jaringan tidak bergantung pada resolusi, dan beberapa kepala klasifikasi dapat digunakan dalam contoh penyempurnaan.  >
>
> b. Semakin tinggi nilai untuk akurasi, presisi, perolehan kembali, dan skor F1, semakin baik.

Cara termudah untuk menggabungkan ketiga model tersebut adalah dengan merata-ratakan probabilitas kelas yang diprediksi. Kemungkinan lain, yang secara teoritis lebih baik, adalah merata-ratakan logit (output lapisan terakhir sebelum aktivasi softmax) dan menerapkan softmax pada rata-rata untuk menghitung probabilitas kelas. Buku catatan contoh menunjukkan kedua opsi tersebut. Pada set data 104 bunga, kinerjanya sama.

| Informasi                                                                                       |
|-------------------------------------------------------------------------------------------------|
| Satu hal yang perlu diperhatikan saat merata-ratakan logit adalah bahwa logit, berbeda dengan probabilitas, tidak dinormalisasi. Logit dapat memiliki nilai yang sangat berbeda dalam model yang berbeda. Menghitung rata-rata tertimbang alih-alih rata-rata sederhana dapat membantu dalam kasus tersebut. Kumpulan data pelatihan harus digunakan untuk menghitung bobot terbaik. |

#### **Rekomendasi Strategi**

Berikut adalah strategi yang kami rekomendasikan untuk mengatasi masalah visi komputer.
Pertama, pilih metode pelatihan berdasarkan ukuran kumpulan data Anda:
- Jika Anda memiliki kumpulan data yang sangat kecil (kurang dari seribu gambar per label), gunakan pembelajaran transfer.
- Jika Anda memiliki kumpulan data berukuran sedang (satu hingga lima ribu gambar per label), gunakan penyetelan halus.
- Jika Anda memiliki kumpulan data yang besar (lebih dari lima ribu gambar per label), latih dari awal

Angka-angka ini adalah aturan praktis dan bervariasi tergantung pada kesulitan kasus penggunaan, kompleksitas model Anda, dan kualitas data. Anda mungkin harus bereksperimen dengan beberapa opsi. Misalnya, kumpulan data 104 bunga memiliki antara seratus hingga tiga ribu gambar per kelas, tergantung pada kelasnya; penyempurnaan masih sangat efektif di dalamnya. 

Apakah Anda melakukan pembelajaran transfer, penyempurnaan, atau pelatihan dari awal, Anda harus memilih arsitektur model. Mana yang harus Anda pilih? 
- Jika Anda ingin membuat lapisan Anda sendiri, mulailah dengan SqueezeNet. Ini adalah model paling sederhana yang akan berkinerja baik. Untuk perangkat edge, Anda biasanya ingin mengoptimalkan model yang dapat diunduh dengan cepat, menempati sangat sedikit ruang di perangkat, dan tidak menimbulkan latensi tinggi selama prediksi.
- Untuk model kecil yang berjalan cepat pada perangkat berdaya rendah, pertimbangkan MobileNetV2.
- Jika Anda tidak memiliki batasan ukuran/kecepatan (seperti jika inferensi akan dilakukan pada sistem cloud penskalaan otomatis) dan menginginkan model terbaik/tercanggih, pertimbangkan Efficient Net.
- Jika Anda termasuk dalam organisasi konservatif yang ingin tetap menggunakan sesuatu yang sudah teruji dan terbukti, pilih ResNet50 atau salah satu variannya yang lebih besar.

Jika biaya pelatihan dan latensi prediksi tidak menjadi perhatian, atau jika peningkatan kecil dalam akurasi model mendatangkan manfaat dari luar, pertimbangkan gabungan tiga model yang saling melengkapi

| Kesimpulan                                                                                       |
|-------------------------------------------------------------------------------------------------|
| Bagian ini berfokus pada metode untuk mengklasifikasikan gambar.  Pertama, dijelaskan bagaimana menggunakan model yang telah dilatih sebelumnya dan mengadaptasinya ke set data baru. Ini adalah metode yang paling umum dan berhasil jika set data pra-pelatihan dan set data target memiliki setidaknya beberapa kesamaan. Kami mempelajari dua bentuk metode ini: pembelajaran transfer, di mana model yang telah dilatih sebelumnya dibekukan dan digunakan sebagai enkoder gambar statis; dan penyempurnaan, di mana bobot model yang telah dilatih sebelumnya digunakan sebagai nilai awal dalam pelatihan baru yang dilakukan pada set data baru.  Kami kemudian meninjau arsitektur klasifikasi gambar AlexNet dan EfficientNet yang paling baru dan lama. Untuk memberi Anda pemahaman lengkap tentang cara kerja model ini, semua blok penyusun arsitektur ini dijelaskan, tentu saja dimulai dengan lapisan konvolusional. Di Bab 4, kita akan melihat penggunaan salah satu arsitektur model gambar ini untuk memecahkan masalah visi komputer umum. |
